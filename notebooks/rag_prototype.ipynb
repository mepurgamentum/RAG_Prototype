{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482e292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\Projects\\RAG Prototype\n",
      "Data path: d:\\Projects\\RAG Prototype\\data\n",
      "Raw data path: d:\\Projects\\RAG Prototype\\data\\raw\\delphic-strategies\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / 'data'\n",
    "RAW_DATA_PATH = DATA_PATH / 'raw' / 'delphic-strategies'\n",
    "PROCESSED_DATA_PATH = DATA_PATH / 'processed'\n",
    "EMBEDDINGS_PATH = DATA_PATH / 'embeddings'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Raw data path: {RAW_DATA_PATH}\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "EMBEDDINGS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe6b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in data/raw/delphic-strategies/:\n",
      "  - Arlington County Business License 2025.pdf (.pdf)\n",
      "  - Business Plan v2.docx (.docx)\n",
      "  - Delphic EIN.pdf (.pdf)\n",
      "  - Expenses.xlsx (.xlsx)\n",
      "  - SDVOSB_approval_letter.pdf (.pdf)\n",
      "  - SOP Executive Communications Intelligence.docx (.docx)\n",
      "  - Va Articles of Organization.pdf (.pdf)\n",
      "  - Va Certificate of Organization.pdf (.pdf)\n",
      "  - Va Certificate.pdf (.pdf)\n",
      "  - Va SCC Filing.pdf (.pdf)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Debug - Check Files\n",
    "print(\"Files in data/raw/delphic-strategies/:\")\n",
    "if RAW_DATA_PATH.exists():\n",
    "    files_found = list(RAW_DATA_PATH.iterdir())\n",
    "    if files_found:\n",
    "        for file in files_found:\n",
    "            print(f\"  - {file.name} ({file.suffix})\")\n",
    "    else:\n",
    "        print(\"  Folder exists but is empty\")\n",
    "        # Create a test file\n",
    "        test_file = RAW_DATA_PATH / \"test_document.txt\"\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"This is a test document about Delphic Strategies. We provide strategic consulting services and business advisory solutions.\")\n",
    "        print(f\"  Created test file: {test_file.name}\")\n",
    "else:\n",
    "    print(f\"  Folder doesn't exist: {RAW_DATA_PATH}\")\n",
    "    RAW_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"  Created folder: {RAW_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff834b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Document Loading Function\n",
    "def load_documents(directory_path):\n",
    "    \"\"\"Load documents from various file types\"\"\"\n",
    "    documents = []\n",
    "    file_names = []\n",
    "    \n",
    "    for file_path in Path(directory_path).glob('**/*'):\n",
    "        if file_path.is_file():\n",
    "            try:\n",
    "                content = \"\"\n",
    "                file_ext = file_path.suffix.lower()\n",
    "                \n",
    "                if file_ext in ['.txt', '.md']:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                \n",
    "                elif file_ext == '.pdf':\n",
    "                    try:\n",
    "                        import PyPDF2\n",
    "                        with open(file_path, 'rb') as file:\n",
    "                            reader = PyPDF2.PdfReader(file)\n",
    "                            for page in reader.pages:\n",
    "                                content += page.extract_text() + \"\\n\"\n",
    "                    except ImportError:\n",
    "                        print(f\"PyPDF2 not installed. Install with: pip install PyPDF2\")\n",
    "                        continue\n",
    "                \n",
    "                elif file_ext in ['.docx', '.doc']:\n",
    "                    try:\n",
    "                        from docx import Document\n",
    "                        doc = Document(file_path)\n",
    "                        for paragraph in doc.paragraphs:\n",
    "                            content += paragraph.text + \"\\n\"\n",
    "                    except ImportError:\n",
    "                        print(f\"python-docx not installed. Install with: pip install python-docx\")\n",
    "                        continue\n",
    "                \n",
    "                elif file_ext in ['.xlsx', '.xls']:\n",
    "                    try:\n",
    "                        import pandas as pd\n",
    "                        df = pd.read_excel(file_path)\n",
    "                        content = df.to_string()\n",
    "                    except ImportError:\n",
    "                        print(f\"openpyxl not installed. Install with: pip install openpyxl\")\n",
    "                        continue\n",
    "                \n",
    "                if content.strip():\n",
    "                    documents.append(content)\n",
    "                    file_names.append(file_path.name)\n",
    "                    print(f\"Loaded: {file_path.name} ({file_ext})\")\n",
    "                else:\n",
    "                    print(f\"No content extracted from: {file_path.name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path.name}: {e}\")\n",
    "    \n",
    "    return documents, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4b1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Delphic Strategies documents...\n",
      "Loaded: Arlington County Business License 2025.pdf (.pdf)\n",
      "Loaded: Business Plan v2.docx (.docx)\n",
      "Loaded: Delphic EIN.pdf (.pdf)\n",
      "Loaded: Expenses.xlsx (.xlsx)\n",
      "Loaded: SDVOSB_approval_letter.pdf (.pdf)\n",
      "Loaded: SOP Executive Communications Intelligence.docx (.docx)\n",
      "Loaded: Va Articles of Organization.pdf (.pdf)\n",
      "Loaded: Va Certificate of Organization.pdf (.pdf)\n",
      "Loaded: Va Certificate.pdf (.pdf)\n",
      "Loaded: Va SCC Filing.pdf (.pdf)\n",
      "Loaded 10 documents\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Documents\n",
    "print(\"Loading Delphic Strategies documents...\")\n",
    "documents, file_names = load_documents(RAW_DATA_PATH)\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "if len(documents) == 0:\n",
    "    print(\"No documents found! Please add PDF, Word, Excel, or text files to data/raw/delphic-strategies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa381d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 27 chunks from 10 documents\n",
      "DataFrame created with 27 rows\n",
      "   document_id                               document_name  chunk_id  \\\n",
      "0            0  Arlington County Business License 2025.pdf         0   \n",
      "1            1                       Business Plan v2.docx         0   \n",
      "2            1                       Business Plan v2.docx         1   \n",
      "3            1                       Business Plan v2.docx         2   \n",
      "4            1                       Business Plan v2.docx         3   \n",
      "\n",
      "                                          chunk_text  \n",
      "0  ARLINGTON COUNTY, VIRGINIA BUSINESS LICENSE TA...  \n",
      "1  Delphic Strategies LLC - Executive Summary Bus...  \n",
      "2  and operational accounts and a strategic commu...  \n",
      "3  Michael served as a strategic communications c...  \n",
      "4  values typically range from $50,000-150,000 de...  \n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Document Chunking\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Process all documents into chunks\n",
    "all_chunks = []\n",
    "chunk_metadata = []\n",
    "\n",
    "for idx, (doc, filename) in enumerate(zip(documents, file_names)):\n",
    "    chunks = chunk_text(doc)\n",
    "    all_chunks.extend(chunks)\n",
    "    \n",
    "    # Track which document each chunk came from\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        chunk_metadata.append({\n",
    "            'document_id': idx,\n",
    "            'document_name': filename,\n",
    "            'chunk_id': chunk_idx,\n",
    "            'chunk_text': chunk\n",
    "        })\n",
    "\n",
    "print(f\"Created {len(all_chunks)} chunks from {len(documents)} documents\")\n",
    "\n",
    "# Create a DataFrame for easy manipulation\n",
    "if chunk_metadata:\n",
    "    chunks_df = pd.DataFrame(chunk_metadata)\n",
    "    print(f\"DataFrame created with {len(chunks_df)} rows\")\n",
    "    print(chunks_df.head())\n",
    "else:\n",
    "    print(\"No chunks created - no documents were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8803f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing search for: 'strategy consulting'\n",
      "Found 3 relevant chunks\n",
      "\n",
      "Document: Business Plan v2.docx\n",
      "Score: 10\n",
      "Text: overhead, limited government experience, slower response times Boutique Crisis Communications Firms: Levick Strategic Communications, Dezenhall Resources Strengths: Crisis specialization, established ...\n",
      "\n",
      "Document: Business Plan v2.docx\n",
      "Score: 8\n",
      "Text: Strategic Content Development LinkedIn thought leadership: Weekly articles on AI-enhanced strategic communications, crisis management best practices, regulatory communications Industry publications: B...\n",
      "\n",
      "Document: Business Plan v2.docx\n",
      "Score: 7\n",
      "Text: values typically range from $50,000-150,000 depending on organizational size and engagement duration. Strategic Partnerships: The firm maintains relationships with management consulting firms, technol...\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Simple Search (only if we have data)\n",
    "if 'chunks_df' in locals() and len(chunks_df) > 0:\n",
    "    def simple_keyword_search(query, chunks_df, top_k=3):\n",
    "        \"\"\"Simple keyword-based search for testing\"\"\"\n",
    "        query_words = query.lower().split()\n",
    "        scores = []\n",
    "        \n",
    "        for chunk in chunks_df['chunk_text']:\n",
    "            chunk_lower = chunk.lower()\n",
    "            score = sum(chunk_lower.count(word) for word in query_words)\n",
    "            scores.append(score)\n",
    "        \n",
    "        chunks_df['relevance_score'] = scores\n",
    "        results = chunks_df.nlargest(top_k, 'relevance_score')\n",
    "        return results[results['relevance_score'] > 0]\n",
    "\n",
    "    # Test simple search\n",
    "    test_query = \"strategy consulting\"\n",
    "    print(f\"Testing search for: '{test_query}'\")\n",
    "    search_results = simple_keyword_search(test_query, chunks_df.copy())\n",
    "    print(f\"Found {len(search_results)} relevant chunks\")\n",
    "\n",
    "    for idx, row in search_results.iterrows():\n",
    "        print(f\"\\nDocument: {row['document_name']}\")\n",
    "        print(f\"Score: {row['relevance_score']}\")\n",
    "        print(f\"Text: {row['chunk_text'][:200]}...\")\n",
    "else:\n",
    "    print(\"Skipping search test - no chunks available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b17dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RAG PROTOTYPE STATUS:\n",
      "✅ Documents loaded and processed successfully!\n",
      "✅ Text chunking completed\n",
      "✅ Basic search functionality working\n",
      "\n",
      "NEXT STEPS:\n",
      "1. Add more documents to data/raw/delphic-strategies/\n",
      "2. Add OpenAI API integration for embeddings\n",
      "3. Implement vector similarity search\n",
      "4. Add LLM for response generation\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Next Steps\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RAG PROTOTYPE STATUS:\")\n",
    "if 'chunks_df' in locals() and len(chunks_df) > 0:\n",
    "    print(\"✅ Documents loaded and processed successfully!\")\n",
    "    print(\"✅ Text chunking completed\")\n",
    "    print(\"✅ Basic search functionality working\")\n",
    "    print(\"\\nNEXT STEPS:\")\n",
    "    print(\"1. Add more documents to data/raw/delphic-strategies/\")\n",
    "    print(\"2. Add OpenAI API integration for embeddings\")\n",
    "    print(\"3. Implement vector similarity search\")\n",
    "    print(\"4. Add LLM for response generation\")\n",
    "else:\n",
    "    print(\"❌ No documents processed\")\n",
    "    print(\"REQUIRED ACTIONS:\")\n",
    "    print(\"1. Add PDF, Word, Excel, or text files to data/raw/delphic-strategies/\")\n",
    "    print(\"2. Re-run the notebook\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f82e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Debugging API Key Loading ===\n",
      "❌ .env file not found\n",
      "\n",
      "=== Loading Environment Variables ===\n",
      "load_dotenv() result: True\n",
      "✅ API key loaded!\n",
      "   Length: 164 characters\n",
      "   Starts with: sk-proj...\n",
      "   Ends with: ...6cwA\n",
      "\n",
      "=== All OPENAI Environment Variables ===\n",
      "OPENAI_API_API_KEY: sk-proj-Uw...\n",
      "OPENAI_API_KEY: sk-proj-Uw...\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: OpenAI Integration Setup\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "# Test OpenAI connection\n",
    "try:\n",
    "    # Test with a simple API call\n",
    "    models = client.models.list()\n",
    "    print(\"✅ OpenAI API connected successfully!\")\n",
    "    print(\"Available models include: gpt-4, gpt-3.5-turbo, text-embedding-3-small\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ OpenAI API connection failed: {e}\")\n",
    "    print(\"Check your API key validity on OpenAI platform\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
